# -*- coding: utf-8 -*-
"""Image_Classfication_Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Huxa95no5sp9wQBdz5iSpBi2V5u2b-h6
"""



# Commented out IPython magic to ensure Python compatibility.
# %cd /content
!nvcc -V
!gcc --version

import torch, torchvision
print(torch.__version__)
print(torch.cuda.is_available())

#  mmcv 설치치
!pip install mmcv -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html

# Commented out IPython magic to ensure Python compatibility.
# Clone mmcls repository
!git clone https://github.com/open-mmlab/mmclassification.git
# %cd mmclassification/

# Install MMClassification from source
!pip install -e .

# Check MMClassification installation
import mmcls
print(mmcls.__version__)

# Confirm the config file exists
!ls configs/mobilenet_v2/mobilenet-v2_8xb32_in1k.py

# config file과 checkpoint 정의

config_file = 'configs/mobilenet_v2/mobilenet-v2_8xb32_in1k.py'
checkpoint_file = 'https://download.openmmlab.com/mmclassification/v0/mobilenet_v2/mobilenet_v2_batch256_imagenet_20200708-3b2dc3af.pth'

import mmcv
from mmcls.apis import inference_model, init_model, show_result_pyplot

device = 'cuda:0'

model = init_model(config_file, checkpoint_file, device=device)

# The model's inheritance relationship
model.__class__.__mro__

"""### Dataset 준비"""

!pip install split-folders

!unzip -q /content/drive/MyDrive/cancer_cls.zip
#학습에 사용할 유방암이 전이된 사진과 전이 되지 않은 사진을 가져온다다

import os
import zipfile
import shutil
import pandas as pd
import numpy as np
import splitfolders
from tqdm.notebook import tqdm

os.makedirs('/content/data', exist_ok=True)
os.makedirs('/content/mmclassification/data', exist_ok=True)
os.makedirs('/content/mmclassification/data/train_imgs/0', exist_ok=True)
os.makedirs('/content/mmclassification/data/train_imgs/1', exist_ok=True)

os.makedirs('/content/mmclassification/data/train_imgs/1', exist_ok=True)
os.makedirs('/content/mmclassification/data/train_imgs/1', exist_ok=True)

os.makedirs('/content/mmclassification/data/train_imgs/0', exist_ok=True)
os.makedirs('/content/mmclassification/data/train_imgs/1', exist_ok=True)

os.makedirs('/content/mmclassification/data/train_imgs/1', exist_ok=True)
os.makedirs('/content/mmclassification/data/train_imgs/1', exist_ok=True)

train_df = pd.read_csv('./train.csv')[['ID', 'N_category']]
train_df
#암이 아직 전이되지 않은 사진는 N_category 0
#암이 전이된 사사진는 N_category 1

label_0 = train_df[train_df.N_category == 0]
label_1 = train_df[train_df.N_category == 1]
label_1
#label_0에는 암이 전이되지 않은 임파선 사진의의 ID를 저장
#label_1에는 암이 전이된된 임파선 사진의의 ID를 저장

label_0

for i, j in tqdm(train_df.values):
  shutil.move(f'/content/mmclassification/train_imgs/{i}.png', f'./data/train_imgs/{j}')
#암이 전이되지 않은 사진과 전이된 사진을 각각 다른 폴더로 이동시킨다

splitfolders.ratio('./data/train_imgs', output="./data/train_imgs", seed=88, ratio=(.8, .2))
for i in range(2):
  shutil.rmtree(f'./data/train_imgs/{i}')
#splitfolders를 통해 train data와 vaildation data를 나눈다
# 현재 코드에서는 train data로 전체의 80%를 사용하고 validation data로 나머지인 20%를 사용한다다

os.listdir('/content/mmclassification/data/train_imgs/train')

# meta file 구축
for i, j in zip(['training_set', 'val_set', 'test_set'], ['train', 'val', 'NONE']):
  os.makedirs(f'./data/dataset/{i}/{i}', exist_ok=True)
  if i == 'test_set':
    break
# for j in ['train', 'val']:
  f = open(f'./data/dataset/{j}.txt', 'w')
  for k in range(2):
    for l in os.listdir(f'./data/train_imgs/{j}/{k}'):
      f.write(f'{k}/{l} {k}\n')
    shutil.move(f'./data/train_imgs/{j}/{k}', f'./data/dataset/{i}/{i}')
  f.close()


f = open('./data/dataset/test.txt', 'w')
for i in os.listdir('./test_imgs'):
  shutil.move(f'./data/test_imgs/{i}', './data/dataset/test_set/test_set')
  f.write(f'{i}\n')
f.close()


f = open('./data/dataset/classes.txt', 'w') # txt파일 경로
for i in range(2):
  f.write(f'{i}\n')
f.close()

shutil.rmtree('./data/train_imgs')
shutil.rmtree('./data/test_imgs')



"""### Read the config file and modify the config

In the [tools tutorial](https://colab.research.google.com/github/open-mmlab/mmclassification/blob/master/docs/tutorials/MMClassification_tools.ipynb), we have introduced all parts of the config file, and here we can modify the loaded config by Python code.
"""

from mmcv import Config
from mmcls.utils import auto_select_device

cfg = Config.fromfile('configs/mobilenet_v2/mobilenet-v2_8xb32_in1k.py')
cfg.device = auto_select_device()

# 입력되는 데이터의 class 갯수를 정의
#해당 프로젝트는 전이 여부의 이진 분류이기에 class 갯수는 2
cfg.model.head.num_classes = 2
cfg.model.head.topk = (1, )

# pre-trained model의 checkpoint를 불러온다.
cfg.model.backbone.init_cfg = dict(type='Pretrained', checkpoint=checkpoint_file, prefix='backbone')

# sample의 크기와 worker의 갯수 정의
cfg.data.samples_per_gpu = 32
cfg.data.workers_per_gpu = 2

# train data의 경로 및 앞서 만들어 놓은 meta file의 경로 정의
cfg.data.train.data_prefix = 'data/dataset/training_set/training_set'
cfg.data.train.ann_file = 'data/dataset/train.txt'
cfg.data.train.classes = 'data/dataset/classes.txt'

# validation data의 경로 및 앞서 만들어 놓은 meta file의 경로 정의
cfg.data.val.data_prefix = 'data/dataset/val_set/val_set'
cfg.data.val.ann_file = 'data/dataset/val.txt'
cfg.data.val.classes = 'data/dataset/classes.txt'

# test data의 경로 및 앞서 만들어 놓은 meta file의 경로 정의
cfg.data.test.data_prefix = 'data/dataset/test_set/test_set'
cfg.data.test.ann_file = 'data/dataset/test.txt'
cfg.data.test.classes = 'data/dataset/classes.txt'




# Specify the normalization parameters in data pipeline
normalize_cfg = dict(type='Normalize', mean=[124.508, 116.050, 106.438], std=[58.577, 57.310, 57.437], to_rgb=True)
cfg.data.train.pipeline[3] = normalize_cfg
cfg.data.val.pipeline[2] = normalize_cfg
cfg.data.test.pipeline[2] = normalize_cfg

# Modify the evaluation metric
cfg.evaluation['metric_options']={'topk': (1, )}

# Specify the optimizer
cfg.optimizer = dict(type='SGD', lr=0.005, momentum=0.9, weight_decay=0.0001)
cfg.optimizer_config = dict(grad_clip=None)

# Specify the learning rate scheduler
cfg.lr_config = dict(policy='step', step=1, gamma=0.1)
cfg.runner = dict(type='EpochBasedRunner', max_epochs=12)

# Specify the work directory
cfg.work_dir = './work_dirs/dataset'

# Output logs for every 10 iterations
cfg.log_config.interval = 10

# Set the random seed and enable the deterministic option of cuDNN
# to keep the results' reproducible.
from mmcls.apis import set_random_seed
cfg.seed = 88
set_random_seed(0, deterministic=True)

cfg.gpu_ids = range(1)

print(f'Config:\n{cfg.pretty_text}')

"""### Fine-tune the model

Use the API `train_model` to fine-tune our model on the cats & dogs dataset.
"""

import time
import mmcv
import os.path as osp

from mmcls.datasets import build_dataset
from mmcls.models import build_classifier
from mmcls.apis import train_model

# work directory 생성성
mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))
# 분류 모델 정의의
model = build_classifier(cfg.model)
model.init_weights()
# 데이터 셋 생성성
datasets = [build_dataset(cfg.data.train)]

model.CLASSES = datasets[0].CLASSES
# Fine tunning: 앞서 정의한 train에 필요한 요소를 모델에에 입력
train_model(
    model,
    datasets,
    cfg,
    distributed=False,
    validate=True,
    timestamp=time.strftime('%Y%m%d_%H%M%S', time.localtime()),
    meta=dict())

"""# Inference"""

model.cfg = cfg

df_submission = pd.read_csv('./data/sample_submission.csv')

for i in tqdm(df_submission.index):
  img = mmcv.imread('./data/dataset/test_set/test_set/' + df_submission.loc[i, 'ID'] + '.png')
  result = inference_model(model, img)
  df_submission.loc[i, 'N_category'] = result['pred_label']
  # df_submission.loc[i, '1'] = result['pred_score']
  # df_submission.loc[i, '2'] = result['pred_class']

# 출력
display(df_submission)

# 저장
df_submission.to_csv('/content/drive/MyDrive/Inference/MMC_base_.csv', index=False)

result